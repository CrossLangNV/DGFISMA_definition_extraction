{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:99% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import shutil\n",
    "import numpy as np\n",
    "#import matplotlib.pyplot as plt\n",
    "#import skimage\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from base64 import b64encode\n",
    "from base64 import b64decode\n",
    "\n",
    "#plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "# make the Jupyter notebook use the full screen width\n",
    "display(HTML(\"<style>.container { width:99% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=\"/notebook/nas-trainings/arne/DGFISMA/DATA/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(10)\n",
    "\n",
    "definitions=open( os.path.join( PATH , \"definition_extraction/bootstrapped_training_set/iteration_1/training_set_def\" ) ).read().strip(\"\\n\").split(\"\\n\")\n",
    "no_definitions=open( os.path.join( PATH , \"definition_extraction/bootstrapped_training_set/iteration_1/training_set_no_def\" ) ).read().strip(\"\\n\").split(\"\\n\")\n",
    "\n",
    "training_set=[]\n",
    "\n",
    "for definition in definitions:\n",
    "    training_set.append( (definition, 1 ) )\n",
    "\n",
    "for no_definition in no_definitions:\n",
    "    training_set.append( (  no_definition, 0 ) )\n",
    "        \n",
    "random.shuffle( training_set )\n",
    "\n",
    "with open( os.path.join(  PATH ,  \"definition_extraction/bootstrapped_training_set/iteration_1/train_dgfisma.csv\" ) , \"w\" ) as f:\n",
    "    for text, label in training_set:\n",
    "        if label==1:\n",
    "            f.write( f'\"{text}\"⚫definition⚫{label}\\n'   )\n",
    "        else:\n",
    "            f.write( f'\"{text}\"⚫no_definition⚫{label}\\n'   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#https://github.com/YipingNUS/DefMiner/blob/master/corpus/wcl_datasets/annotated/wiki_combined.txt\n",
    "\n",
    "training_set=[]\n",
    "\n",
    "wikipedia_def=open( os.path.join( PATH, \"definition_extraction/bootstrapped_training_set/wikipedia_definitions\" )    ).read().strip(\"\\n\").split(\"\\n\")\n",
    "for sentence in wikipedia_def:\n",
    "    if \"/DEF\" in sentence:\n",
    "        sentence=sentence.replace( \"/TERM\", \"\").replace( \"/DEF\", \"\" ).replace( \"/O\", \"\" ).replace( \"-LBR-\" , \"(\" ).replace( \"-RBR-\", \")\" ).replace( \"&amp\", \"&\").replace( \"&nbsp\", \" \")\n",
    "        training_set.append( ( sentence, 1  )   )\n",
    "    else:\n",
    "        training_set.append( ( sentence, 0  )   )\n",
    "        \n",
    "with open( os.path.join( PATH, \"definition_extraction/bootstrapped_training_set/iteration_1/train_wiki.csv\"   )  , \"w\" ) as f:\n",
    "    for text, label in training_set:\n",
    "        if label==1:\n",
    "            f.write( f'\"{text}\"⚫definition⚫{label}\\n'   )\n",
    "        else:\n",
    "            f.write( f'\"{text}\"⚫no_definition⚫{label}\\n'   )      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /notebook/nas-trainings/arne/DGFISMA/DATA/definition_extraction/bootstrapped_training_set/iteration_1/train_dgfisma.csv /notebook/nas-trainings/arne/DGFISMA/DATA/definition_extraction/bootstrapped_training_set/iteration_1/train_wiki.csv > /notebook/nas-trainings/arne/DGFISMA/DATA/definition_extraction/bootstrapped_training_set/iteration_1/train_dgfisma_wiki.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-30 13:06:54.994096: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2020-06-30 13:06:54.994182: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2020-06-30 13:06:54.994191: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Using TensorFlow backend.\n",
      "Lock 140282263617208 acquired on /root/.cache/torch/transformers/a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.8949e27aafafa845a18d98a0e3a88bc2d248bbc32a1b75947366664658f23b1c.lock\n",
      "https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpepz5d3it\n",
      "Downloading: 100%|██████████████████████████████| 442/442 [00:00<00:00, 189kB/s]\n",
      "storing https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-config.json in cache at /root/.cache/torch/transformers/a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.8949e27aafafa845a18d98a0e3a88bc2d248bbc32a1b75947366664658f23b1c\n",
      "creating metadata file for /root/.cache/torch/transformers/a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.8949e27aafafa845a18d98a0e3a88bc2d248bbc32a1b75947366664658f23b1c\n",
      "Lock 140282263617208 released on /root/.cache/torch/transformers/a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.8949e27aafafa845a18d98a0e3a88bc2d248bbc32a1b75947366664658f23b1c.lock\n",
      "loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-config.json from cache at /root/.cache/torch/transformers/a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.8949e27aafafa845a18d98a0e3a88bc2d248bbc32a1b75947366664658f23b1c\n",
      "Model config DistilBertConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"dim\": 768,\n",
      "  \"do_sample\": false,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"tie_weights_\": true,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "Lock 140282263614688 acquired on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
      "https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpcy2ji021\n",
      "Downloading: 100%|████████████████████████████| 232k/232k [00:00<00:00, 698kB/s]\n",
      "storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt in cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "creating metadata file for /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "Lock 140282263614688 released on /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084.lock\n",
      "loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "tokenizing...\n",
      "Lock 140282263664176 acquired on /root/.cache/torch/transformers/7b8a8f0b21c4e7f6962451c9370a5d9af90372a5f64637a251f2de154d0fc72c.c2015533705b9dff680ae707e205a35e2860e8d148b45d35085419d74fe57ac5.lock\n",
      "https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp9x4sfr5f\n",
      "Downloading: 100%|███████████████████████████| 268M/268M [00:09<00:00, 29.7MB/s]\n",
      "storing https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-pytorch_model.bin in cache at /root/.cache/torch/transformers/7b8a8f0b21c4e7f6962451c9370a5d9af90372a5f64637a251f2de154d0fc72c.c2015533705b9dff680ae707e205a35e2860e8d148b45d35085419d74fe57ac5\n",
      "creating metadata file for /root/.cache/torch/transformers/7b8a8f0b21c4e7f6962451c9370a5d9af90372a5f64637a251f2de154d0fc72c.c2015533705b9dff680ae707e205a35e2860e8d148b45d35085419d74fe57ac5\n",
      "Lock 140282263664176 released on /root/.cache/torch/transformers/7b8a8f0b21c4e7f6962451c9370a5d9af90372a5f64637a251f2de154d0fc72c.c2015533705b9dff680ae707e205a35e2860e8d148b45d35085419d74fe57ac5.lock\n",
      "loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/distilbert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/transformers/7b8a8f0b21c4e7f6962451c9370a5d9af90372a5f64637a251f2de154d0fc72c.c2015533705b9dff680ae707e205a35e2860e8d148b45d35085419d74fe57ac5\n",
      "Weights of DistilBertSequenceClassifier not initialized from pretrained model: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "Weights from pretrained model not used in DistilBertSequenceClassifier: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "Epoch:   0%|                                             | 0/10 [00:00<?, ?it/s]epoch: 1\n",
      "Train loss: 0.1842229575394912\n",
      "Validation Accuracy: 0.9641544117647058\n",
      "\n",
      "\n",
      "Epoch:  10%|███▋                                 | 1/10 [00:36<05:29, 36.64s/it]epoch: 2\n",
      "Train loss: 0.08938450046948024\n",
      "Validation Accuracy: 0.9669117647058824\n",
      "\n",
      "\n",
      "Epoch:  20%|███████▍                             | 2/10 [01:13<04:53, 36.74s/it]epoch: 3\n",
      "Train loss: 0.06726552198704024\n",
      "Validation Accuracy: 0.9696691176470589\n",
      "\n",
      "\n",
      "Epoch:  30%|███████████                          | 3/10 [01:51<04:18, 36.95s/it]epoch: 4\n",
      "Train loss: 0.05380332813759271\n",
      "Validation Accuracy: 0.9733455882352942\n",
      "\n",
      "\n",
      "Epoch:  40%|██████████████▊                      | 4/10 [02:29<03:43, 37.28s/it]epoch: 5\n",
      "Train loss: 0.041284331118800026\n",
      "Validation Accuracy: 0.9751838235294118\n",
      "\n",
      "\n",
      "Epoch:  50%|██████████████████▌                  | 5/10 [03:07<03:08, 37.61s/it]epoch: 6\n",
      "Train loss: 0.04188580449698563\n",
      "Validation Accuracy: 0.9715073529411765\n",
      "\n",
      "\n",
      "Epoch:  60%|██████████████████████▏              | 6/10 [03:46<02:31, 37.89s/it]epoch: 7\n",
      "Train loss: 0.03345568233897867\n",
      "Validation Accuracy: 0.9761029411764706\n",
      "\n",
      "\n",
      "Epoch:  70%|█████████████████████████▉           | 7/10 [04:24<01:54, 38.12s/it]epoch: 8\n",
      "Train loss: 0.02488009228294057\n",
      "Validation Accuracy: 0.9724264705882353\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|█████████████████████████████▌       | 8/10 [05:03<01:16, 38.30s/it]epoch: 9\n",
      "Train loss: 0.01849788731958409\n",
      "Validation Accuracy: 0.9742647058823529\n",
      "\n",
      "\n",
      "Epoch:  90%|█████████████████████████████████▎   | 9/10 [05:42<00:38, 38.43s/it]epoch: 10\n",
      "Train loss: 0.016914490617363526\n",
      "Validation Accuracy: 0.9751838235294118\n",
      "\n",
      "\n",
      "Epoch: 100%|████████████████████████████████████| 10/10 [06:20<00:00, 38.09s/it]\n",
      "saving model in ../bert_classifier/models_dgfisma_def_extraction/run_2020_06_30_13_06_55_11f36c372745/distilbert-base-uncased_model_10.pth\n",
      "Configuration saved in ../bert_classifier/models_dgfisma_def_extraction/run_2020_06_30_13_06_55_11f36c372745/config.json\n"
     ]
    }
   ],
   "source": [
    "!python ../bert_classifier/src/train.py  \\\n",
    "--filename \"/notebook/nas-trainings/arne/DGFISMA/DATA/definition_extraction/bootstrapped_training_set/iteration_1/train_dgfisma_wiki.csv\"   \\\n",
    "--model_storage_directory '../bert_classifier/models_dgfisma_def_extraction' \\\n",
    "--device \"cuda:0\" \\\n",
    "--train_bert \"last_layer\" \\\n",
    "--epochs 10 \\\n",
    "--delimiter ⚫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-30 13:18:16.593421: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2020-06-30 13:18:16.593505: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2020-06-30 13:18:16.593517: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Using TensorFlow backend.\n",
      "loading ../bert_classifier/models_dgfisma_def_extraction/run_2020_06_30_13_06_55_11f36c372745/distilbert-base-uncased_model_10.pth\n",
      "tokenizing...\n",
      "start inference...\n",
      "6.423940420150757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        29\n",
      "           1       0.96      0.93      0.95        29\n",
      "\n",
      "   micro avg       0.95      0.95      0.95        58\n",
      "   macro avg       0.95      0.95      0.95        58\n",
      "weighted avg       0.95      0.95      0.95        58\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "start=time.time()\n",
    "\n",
    "!python ../bert_classifier/src/predict.py  \\\n",
    "--filename \"/notebook/nas-trainings/arne/DGFISMA/DATA/definition_extraction/bootstrapped_training_set/iteration_1/test_sentences\"  \\\n",
    "--model_path \"../bert_classifier/models_dgfisma_def_extraction/run_2020_06_30_13_06_55_11f36c372745/distilbert-base-uncased_model_10.pth\" \\\n",
    "--device \"cuda:0\"  \\\n",
    "--output_file \"/notebook/nas-trainings/arne/DGFISMA/DATA/definition_extraction/bootstrapped_training_set/iteration_1/test_sentences_predict\" \\\n",
    "--batch_size 32\n",
    "\n",
    "end=time.time()\n",
    "print( end-start )\n",
    "\n",
    "test_sentences_predict=open( \"/notebook/nas-trainings/arne/DGFISMA/DATA/definition_extraction/bootstrapped_training_set/iteration_1/test_sentences_predict\"  ).read().strip( \"\\n\" ).split( \"\\n\" )\n",
    "test_sentences_predict = [ int(label.split()[0]) for label in test_sentences_predict ]\n",
    "\n",
    "test_labels=open( \"/notebook/nas-trainings/arne/DGFISMA/DATA/definition_extraction/bootstrapped_training_set/iteration_1/test_labels\"  ).read().strip( \"\\n\" ).split( \"\\n\" )\n",
    "test_labels=[ int(label)  for label in test_labels  ]\n",
    "\n",
    "print( classification_report( test_labels, test_sentences_predict   )  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Permformance when using Fasttext (on the same test set):\n",
    "\n",
    "( see http://localhost:8005/notebooks/nas-trainings/arne/DGFISMA/definition_extraction/notebooks/test_fasttext_classifier.ipynb)\n",
    "\n",
    "Use this dockerfile:\n",
    "\n",
    "/nas-trainings/arne/DGFISMA/definition_extraction/Dockerfile\n",
    "\n",
    "\n",
    "             precision    recall  f1-score   support\n",
    "\n",
    "           0       0.74      0.86      0.79        29\n",
    "           1       0.83      0.69      0.75        29\n",
    "\n",
    "   micro avg       0.78      0.78      0.78        58 <br/>\n",
    "   macro avg       0.78      0.78      0.77        58 <br/>\n",
    "weighted avg       0.78      0.78      0.77        58 <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " 0       0.88      1.00      0.94        29\n",
    "           1       1.00      0.86      0.93        29\n",
    "\n",
    "   micro avg       0.93      0.93      0.93        58\n",
    "   macro avg       0.94      0.93      0.93        58\n",
    "weighted avg       0.94      0.93      0.93        58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from cleaning import clean_html, delete_annexes\n",
    "\n",
    "http=\"https://eur-lex.europa.eu/legal-content/EN/ALL/?uri=CELEX:32015R0063\"\n",
    "\n",
    "http=\"https://eur-lex.europa.eu/legal-content/EN/ALL/?uri=celex:32018R0815\"\n",
    "\n",
    "\n",
    "http=\"https://eur-lex.europa.eu/legal-content/EN/ALL/?uri=celex:52018SC0073\"\n",
    "\n",
    "http= \"https://eur-lex.europa.eu/legal-content/EN/ALL/?uri=celex:52017PC0790\"\n",
    "\n",
    "page_response=requests.get( http )\n",
    "\n",
    "articles=clean_html( page_response.content.decode( 'utf-8' ) )\n",
    "articles=delete_annexes(articles  )\n",
    "articles=\"\\n\".join(articles)\n",
    "\n",
    "with open( os.path.join(  \"/notebook/nas-trainings/arne/DGFISMA/definition_extraction/notebooks/bootstrapped_training_set/iteration_1/\", \"eurlex_text_celex:52017PC0790\" ) , \"w\" ) as f:\n",
    "        f.write(  articles  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open an Eurlex document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
